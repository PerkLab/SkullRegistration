{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from local_vars import root_folder\n",
    "\n",
    "import os\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "images_folder = \"SkullScan1_Images\"\n",
    "images_fullpath = os.path.join(root_folder, images_folder)\n",
    "\n",
    "segmentation_threshold = 0.8 \n",
    "minimum_distance = 2\n",
    "\n",
    "deep_learning_model_path = \"\"\n",
    "deep_learning_weights_path = \"C:/Users/14ams18/Documents/weights_2019-04-08_13-48-19.h5\"\n",
    "\n",
    "input_image_size = 128\n",
    "input_intensity_scaling = 1 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\14ams18\\Anaconda3\\envs\\SkullRegistration\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\14ams18\\Anaconda3\\envs\\SkullRegistration\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#If loading full model instead of just weights\n",
    "#model = load_model(deep_learning_model_path)\n",
    "\n",
    "#If loading weights instead of a saved model\n",
    "feature_n = 512\n",
    "step_size = 1e-5\n",
    "\n",
    "def unet(pretrained_weights = None, input_size = (input_image_size, input_image_size, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(feature_n // 16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(feature_n // 16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(feature_n // 8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(feature_n // 8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(feature_n // 4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(feature_n // 4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(feature_n // 2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(feature_n // 2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(feature_n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(feature_n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(feature_n // 2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(feature_n // 2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(feature_n // 2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(feature_n // 4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(feature_n // 4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(feature_n // 4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(feature_n // 8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(feature_n // 8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(feature_n // 8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(feature_n // 16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(feature_n // 16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(feature_n // 16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = step_size), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet(deep_learning_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files and saving them in numpy arrays...\n"
     ]
    }
   ],
   "source": [
    "image_file_list = [f for f in os.listdir(images_fullpath) if f.endswith('.png')]\n",
    "n = len(image_file_list)\n",
    "\n",
    "image_data = np.zeros([n, input_image_size, input_image_size, 1]).astype(np.uint8)\n",
    "\n",
    "print(\"Reading files and saving them in numpy arrays...\")\n",
    "\n",
    "for i in range(n):\n",
    "    current_file_name = image_file_list[i]\n",
    "    current_file_path = os.path.join(images_fullpath, current_file_name)\n",
    "    image = cv2.imread(current_file_path, 0)\n",
    "    if image is None:\n",
    "        print(\"File not read: {}\".format(current_file_path))\n",
    "        break\n",
    "    if image.shape[0] != input_image_size or image.shape[1] != input_image_size:\n",
    "        image_data[i][:,:,0] = cv2.resize(image, (input_image_size, input_image_size)).astype(np.uint8)\n",
    "    else:\n",
    "        image_data[i][:,:,0] = image.astype(np.uint8)\n",
    "    \n",
    "\n",
    "image_data = image_data * input_intensity_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = model.predict(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    for j in range(input_image_size):\n",
    "        for k in range(input_image_size):\n",
    "            if segmentations[i,j,k] < segmentation_threshold:\n",
    "                segmentations[i,j,k] = 0\n",
    "            else:\n",
    "                segmentations[i,j,k] = 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations_output_file = os.path.join(images_fullpath, \"segmentations\")\n",
    "np.save(segmentations_output_file, segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
